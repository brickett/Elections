## Step 3: Training a model on the data ----
interests <- teens[5:40]
interests_z <- as.data.frame(lapply(interests, scale))
teen_clusters <- kmeans(interests_z, 5) #the number of clusters is predetermined - e.g. firm wants five segments
## Step 4: Evaluating model performance ----
# look at the size of the clusters
teen_clusters$size
# look at the cluster centers
teen_clusters$centers
teen_clusters <- kmeans(interests_z, 6) #the number of clusters is predetermined - e.g. firm wants five segments
## Step 4: Evaluating model performance ----
# look at the size of the clusters - how many values are in each
teen_clusters$size
# look at the cluster centers - the higher the number, the higher the prevalence of a keyword in a given cluster. Negative numbers are below the average
teen_clusters$centers
## Step 5: Improving model performance ----
# apply the cluster IDs to the original data frame
teens$cluster <- teen_clusters$cluster
# look at the first five records
teens[1:5, c("cluster", "gender", "age", "friends")]
# mean age by cluster
aggregate(data = teens, age ~ cluster, mean)
# proportion of females by cluster
aggregate(data = teens, female ~ cluster, mean)
# mean number of friends by cluster
aggregate(data = teens, friends ~ cluster, mean)
# What else can we see
str(teen_clusters)
kmeans.wss.k <- function(interests_z, k){
km = kmeans(interests_z, k)
return (km$tot.withinss)
}
kmeans.wss.k(interests_z, 5)
kmeans.wss.k(interests_z, 4)
kmeans.dis <- function(data_z, maxk){
dis=(nrow(data_z)-1)*sum(apply(data_z,2,var))
dis[2:maxk]=sapply (2:maxk, kmeans.wss.k, interests_z=interests_z)
return(dis) }
maxk = 30
dis = kmeans.dis(interests_z, maxk)
plot(1:maxk, dis, type='b', xlab="Number of Clusters", ylab="Distortion", col="blue")
#set wd
setwd("~/Academics Grad School/TO 567 Data Mining/Classwork/9")
## Import Data
setwd("~/Academics Grad School/TO 567 Data Mining/HW/G1")
fights <- read.csv("FightData.csv")
str(fights)
#clean data
library(lubridate)
fights$DOB.x <- mdy(fights$DOB.x)
fights$DOB.y <- mdy(fights$DOB.y)
summary(fights)
#Replace NAs
fights$Height.x <- ifelse(is.na(fights$Height.x), mean(fights$Height.x, na.rm = TRUE), fights$Height.x)
fights$Weight.x <- ifelse(is.na(fights$Weight.x), mean(fights$Weight.x, na.rm = TRUE), fights$Weight.x)
fights$Reach.x <- ifelse(is.na(fights$Reach.x), mean(fights$Reach.x, na.rm = TRUE), fights$Reach.x)
fights$DOB.x <- ifelse(is.na(fights$DOB.x), mean(fights$DOB.x, na.rm = TRUE), fights$DOB.x)
fights$Height.y <- ifelse(is.na(fights$Height.y), mean(fights$Height.y, na.rm = TRUE), fights$Height.y)
fights$Weight.y <- ifelse(is.na(fights$Weight.y), mean(fights$Weight.y, na.rm = TRUE), fights$Weight.y)
fights$Reach.y <- ifelse(is.na(fights$Reach.y), mean(fights$Reach.y, na.rm = TRUE), fights$Reach.y)
fights$DOB.y <- ifelse(is.na(fights$DOB.y), mean(fights$DOB.y, na.rm = TRUE), fights$DOB.y)
open_stance <- (11+18)/(6230*2 - 412 - 398)
orthodox_stance <- (4457+4547)/(6230*2 - 412 - 398)
sideways_stance <- (3+3)/(6230*2 - 412 - 398)
southpaw_stance <- (1194+1151)/(6230*2 - 412 - 398)
switch_stance <- (113+153)/(6230*2 - 412 - 398)
set.seed(123)
fights$stancex_gen <- runif(nrow(fights))
fights$stancey_gen <- runif(nrow(fights))
fights$stancey_gen <- ifelse(as.numeric(fights$stancey_gen) <= open_stance & !is.na(as.numeric(fights$stancey_gen)), "Open Stance", fights$stancey_gen)
fights$stancey_gen <- ifelse(as.numeric(fights$stancey_gen) <= open_stance + orthodox_stance & !is.na(as.numeric(fights$stancey_gen)), "Orthodox", fights$stancey_gen)
fights$stancey_gen <- ifelse(as.numeric(fights$stancey_gen) <= open_stance + orthodox_stance + sideways_stance & !is.na(as.numeric(fights$stancey_gen)), "Sideways", fights$stancey_gen)
fights$stancey_gen <- ifelse(as.numeric(fights$stancey_gen) <= open_stance + orthodox_stance + sideways_stance + southpaw_stance & !is.na(as.numeric(fights$stancey_gen)), "Southpaw", fights$stancey_gen)
fights$stancey_gen <- ifelse(as.numeric(fights$stancey_gen) <= open_stance + orthodox_stance + sideways_stance + southpaw_stance + switch_stance & !is.na(as.numeric(fights$stancey_gen)), "Switch", fights$stancey_gen)
fights$Stance.y <- ifelse(is.na(fights$Stance.y), fights$stancey_gen, fights$Stance.y)
fights$stancex_gen <- ifelse(as.numeric(fights$stancex_gen) <= open_stance & !is.na(as.numeric(fights$stancex_gen)), "Open Stance", fights$stancex_gen)
fights$stancex_gen <- ifelse(as.numeric(fights$stancex_gen) <= open_stance + orthodox_stance & !is.na(as.numeric(fights$stancex_gen)), "Orthodox", fights$stancex_gen)
fights$stancex_gen <- ifelse(as.numeric(fights$stancex_gen) <= open_stance + orthodox_stance + sideways_stance & !is.na(as.numeric(fights$stancex_gen)), "Sideways", fights$stancex_gen)
fights$stancex_gen <- ifelse(as.numeric(fights$stancex_gen) <= open_stance + orthodox_stance + sideways_stance + southpaw_stance & !is.na(as.numeric(fights$stancex_gen)), "Southpaw", fights$stancex_gen)
fights$stancex_gen <- ifelse(as.numeric(fights$stancex_gen) <= open_stance + orthodox_stance + sideways_stance + southpaw_stance + switch_stance & !is.na(as.numeric(fights$stancex_gen)), "Switch", fights$stancex_gen)
fights$Stance.x <- ifelse(is.na(fights$Stance.x), fights$stancex_gen, fights$Stance.x)
# Factorize
fights$result <- as.factor(fights$result)
fights$Stance.x <- as.factor(fights$Stance.x)
fights$Stance.y <- as.factor(fights$Stance.y)
#Create variables
#relative height
fights$rel_height <- fights$Height.x - fights$Height.y
#relative reach
fights$rel_reach <- fights$Reach.x - fights$Reach.y
#relative age
fights$rel_age <- fights$DOB.x - fights$DOB.y
#relative weight
fights$rel_weight <- fights$Weight.x - fights$Weight.y
#same stance
fights$rel_stance <- ifelse(fights$Stance.x == fights$Stance.y, "Same", "Different")
#landed - absorbed
fights$rel_hits <- fights$SLpM.x - fights$SApM.y
#striking accuracy
fights$rel_striking <- fights$Str..Acc..x - fights$Str..Def..y
#TDA - TDD
fights$rel_TD <- fights$TD.Acc..x - fights$TD.Def..y
#TD average
fights$rel_TD_freq <- fights$TD.Avg..x - fights$TD.Avg..y
#Submission average
fights$rel_sub <- fights$Sub..Avg..x - fights$Sub..Avg..y
#Test/Train Split
#70-30 split
set.seed(567)
train_set <- sample(1:nrow(fights), 0.7*nrow(fights))
#Training set
train_fights <- fights[train_set, ]
x_tr <- fights[train_set,-1] #x only
y_tr <- fights[train_set,1] # y only
#Validation set
val_fights <- fights[-train_set, ]
x_val <- fights[-train_set,-1]  #x only
y_val <- fights[-train_set,1]   #y only
#Create Model
#m1 Relative only
formula1 <- result ~ rel_age + rel_height + rel_reach + rel_weight + rel_stance + rel_hits +
rel_TD + rel_striking + rel_TD_freq + rel_sub
m1 <- glm(formula1, data = train_fights, family = "binomial")
summary(m1)
m1_val <- predict(m1, val_fights, type = "response")
val_fights_m1 <- cbind(val_fights, m1_val)
result_m1 <- ifelse(val_fights_m1$m1_val>=0.5,"win","loss")
val_fights_m1 <- cbind(val_fights, result_m1)
val_fights_m1$result_m1 <- as.factor(val_fights_m1$result_m1)
mean(val_fights_m1$result == val_fights_m1$result_m1, na.rm = TRUE) #accuracy was 0.5966899 without replacing NAs
#m2 Relative + absolute
formula2 <- result ~ rel_age + rel_height + rel_reach + rel_weight + rel_stance + rel_hits +
rel_TD + rel_striking + rel_TD_freq + rel_sub + SLpM.x + Str..Acc..x + SApM.x + Str..Def..x +
TD.Avg..x + TD.Acc..x + TD.Def..x + Sub..Avg..x
m2 <- glm(formula2, data = train_fights, family = "binomial")
summary(m2)
m2_val <- predict(m2, val_fights, type = "response")
val_fights_m2 <- cbind(val_fights, m2_val)
result_m2 <- ifelse(val_fights_m2$m2_val>=0.5,"win","loss")
val_fights_m2 <- cbind(val_fights, result_m2)
val_fights_m2$result_m2 <- as.factor(val_fights_m2$result_m2)
mean(val_fights_m2$result == val_fights_m2$result_m2, na.rm = TRUE) #accuracy was 0.5966899 without replacing NAs
mean(fights$rel_weight)
fights$Age.x <- today() - fights$DOB.x
fights$Age.y <- today() - fights$DOB.y
performance_test <- function(model, cutoff) {
m_val <- predict(model, val_fights, type = "response")
val_fights_m <- cbind(val_fights, m_val)
result_m <- ifelse(val_fights_m$m_val>=cutoff,"win","loss")
val_fights_m <- cbind(val_fights, result_m)
val_fights_m$result_m <- as.factor(val_fights_m$result_m)
results_mean <- mean(val_fights_m$result == val_fights_m$result_m, na.rm = TRUE)
return(list(val_fights_m, results_mean))
}
performance_test(m2,0.5)
list[val_fights_m2, rmean_m2] <- performance_test(m2,0.5)
library(gsubfn)
install.packages("gsubfn")
list[val_fights_m2, rmean_m2] <- performance_test(m2,0.5)
library(gsubfn)
list[val_fights_m2, rmean_m2] <- performance_test(m2,0.5)
View(list)
list[val_fights_m2, rmean_m2] <- performance_test(m2,0.5)
funout <- performance_test(m2,0.5)
val_fights_m2 <- funout[1]
rmean_m2 <- funout[2]
rmean_m2
funout <- performance_test(m1,0.5)
val_fights_m1 <- funout[1]
rmean_m1 <- funout[2] #accuracy was 0.5966899 without replacing NAs
m2_test <- data.frame()
m2_test <- data.frame()
for (i in seq(0, 1, length.out = 10))
for (i in seq(0, 1, length.out = 10)):
{
funout <- performance_test(m2, i)
rbind(m2_test, c(i,funout[2]))
}
for (i in seq(0, 1, length.out = 10)) {
funout <- performance_test(m2, i)
rbind(m2_test, c(i,funout[2]))
}
m2_test <- data.frame()
for (i in seq(0, 1, length.out = 10)) {
funout <- performance_test(m2, i)
rbind(m2_test, c(i,funout[2]))
}
funout[2]
funout[2][1]
funout[2]^2
(funout[2])^2
hmm <- funout[2]
return(list(valuation = val_fights_m, accuracy = results_mean))
performance_test <- function(model, cutoff) {
m_val <- predict(model, val_fights, type = "response")
val_fights_m <- cbind(val_fights, m_val)
result_m <- ifelse(val_fights_m$m_val>=cutoff,"win","loss")
val_fights_m <- cbind(val_fights, result_m)
val_fights_m$result_m <- as.factor(val_fights_m$result_m)
results_mean <- mean(val_fights_m$result == val_fights_m$result_m, na.rm = TRUE)
return(list(valuation = val_fights_m, accuracy = results_mean))
}
funout <- performance_test(m2,0.5)
val_fights_m2 <- funout$valuation
rmean_m2 <- funout$accuracy
hmm <- rmean_m2[11]
hmm <- rmean_m2[1]
m2_test <- data.frame()
for (i in seq(0, 1, length.out = 10)) {
funout <- performance_test(m2, i)
rbind(m2_test, c(i,funout$accuracy[1]))
}
for (i in seq(0.01, 1, length.out = 100)) {
funout <- performance_test(m2, i)
rbind(m2_test, c(i,funout$accuracy[1]))
}
for (i in seq(0.01, 1, length.out = 100)) {
print(i)
#funout <- performance_test(m2, i)
#rbind(m2_test, c(i,funout$accuracy[1]))
}
for (i in seq(0.01, 1, length.out = 100)) {
funout <- performance_test(m2, i)
print(funout$accuracy[1])
#rbind(m2_test, c(i,funout$accuracy[1]))
}
rbind(m2_test, c(0.01,0.5115035))
m2_test <- data.frame()
for (i in seq(0.01, 1, length.out = 100)) {
funout <- performance_test(m2, i)
print(funout$accuracy[1])
m2_test <- rbind(m2_test, c(i,funout$accuracy[1]))
}
for (i in seq(0.01, 0.99, length.out = 99)) {
funout <- performance_test(m2, i)
m2_test <- rbind(m2_test, c(i,funout$accuracy[1]))
}
m2_test <- data.frame()
for (i in seq(0.01, 0.99, length.out = 99)) {
funout <- performance_test(m2, i)
m2_test <- rbind(m2_test, c(i,funout$accuracy[1]))
}
m2_test <- data.frame()
names(m2_test) <- c("i", "accuracy")
m2_test <- data.frame()
for (i in seq(0.01, 0.99, length.out = 99)) {
funout <- performance_test(m2, i)
m2_test <- rbind(m2_test, c(i,funout$accuracy[1]))
}
names(m2_test) <- c("i", "accuracy")
plot(m2_test$i, m2_test$accuracy)
m2_test$i[m2_test$accuracy == max(m2_test$accuracy)]
# import the CSV file
wbcd <- read.csv("wbcd.csv")
#set wd
setwd("~/Academics Grad School/TO 567 Data Mining/Classwork/9")
d
# import the CSV file
wbcd <- read.csv("wbcd.csv")
head(wbcd)
str(wbcd)
table(wbcd$diagnosis)
round(prop.table(table(wbcd$diagnosis)),3)
#set wd
setwd("~/Academics Grad School/TO 567 Data Mining/Classwork/9")
# import the CSV file
wbcd <- read.csv("wisc_bc_data.csv", stringsAsFactors = FALSE)
str(wbcd) # Lets check what we have in this dataset
#First column is the randomly generated Patient ID
#Get rid of it
wbcd$id <- NULL
# table or proportions with more informative labels
table(wbcd$diagnosis)
wbcd$diagnosis <- factor(wbcd$diagnosis, levels = c("B", "M"),
labels = c("Benign", "Malignant"))
round(prop.table(table(wbcd$diagnosis)) * 100, 1)
# summarize three numeric features
summary(wbcd[c("radius_mean", "area_mean", "smoothness_mean")])
#Given substantial scale differences, we need to normalize the data
#Function for Min-Max Normalization
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
#Applying normalization function to all columns except the response variable
wbcd_n <- as.data.frame(lapply(wbcd[2:ncol(wbcd)], normalize))
#Checking whether scale differences persist
summary(wbcd_n[c("radius_mean", "area_mean", "smoothness_mean")])
#Set a seed for random number generator for consistent output
set.seed(123)
#Selects 100 random rows for test data
test_set <- sample(1:nrow(wbcd_n), 100)
# Create a train set and test set
#First the predictors
wbcd_train <- wbcd_n[-test_set, ]
wbcd_test <- wbcd_n[test_set, ]
#Now the response (aka Labels)
wbcd_train_labels <- wbcd[-test_set, "diagnosis"]
wbcd_test_labels <- wbcd[test_set, "diagnosis"]
#Lets run the KNN command
library(class)
library(caret)
#Run KNN on train data, create predictions for test data
#Starting K value close to sqrt(nrow(wbcd_train))
sqrt(nrow(wbcd_train))
wbcd_test_pred <- knn(train = wbcd_train, test = wbcd_test,
cl = wbcd_train_labels, k=21)
#Evaluate model results
library(gmodels)
CrossTable(x = wbcd_test_labels, y = wbcd_test_pred,
prop.chisq=FALSE)
# Accuracy: Overall, how often is the classifier correct?
(62 + 33) / (62 + 33 + 5 + 0)
# Error rate: Overall, how often is it wrong?
(5 + 0) / (62 + 33 + 5 + 0)
# error rate = 1 - accuracy
1 - 0.95
# Kappa statistic: This is essentially a measure of how well the classifier performed as compared to how well it would have performed simply by chance.
pr_a <- (0.62 + 0.33)
pr_a
pr_e <- 0.62*0.67 + 0.38*0.33
pr_e
k <- (pr_a - pr_e) / (1 - pr_e)
k
# Sensitivity: When it's actually yes, how often does it predict yes?
sens <- 33 / (33 + 5)
sens
# Specificity: When it's actually no, how often does it predict no?
spec <- 62 / (62 + 0)
spec
# Precision: When it predicts yes, how often is it correct?
prec <- 33 / (33 + 0)
prec
# example using the caret package
confusionMatrix(wbcd_test_pred, wbcd_test_labels, positive = "Malignant")
# example using the caret package
confusionMatrix(wbcd_test_pred, wbcd_test_labels, positive = "Malignant")
library(caret)
# example using the caret package
confusionMatrix(wbcd_test_pred, wbcd_test_labels, positive = "Malignant")
#Using Z-Score Normalization
wbcd_z <- as.data.frame(scale(wbcd[2:ncol(wbcd)]))
# example using the caret package
confusionMatrix(wbcd_test_pred, wbcd_test_labels, positive = "Malignant")
install.packages("e1071")
# example using the caret package
confusionMatrix(wbcd_test_pred, wbcd_test_labels, positive = "Malignant")
#set wd
setwd("~/Academics Grad School/TO 567 Data Mining/Classwork/10")
## Step 2: Exploring and preparing the data ----
# read in data and examine structure
concrete <- read.csv("concrete.csv")
str(concrete)
# custom normalization function
normalize <- function(x) {
return((x - min(x)) / (max(x) - min(x)))
}
# apply normalization to entire data frame
concrete_norm <- as.data.frame(lapply(concrete, normalize))
# confirm that the range is now between zero and one
summary(concrete_norm$strength)
# compared to the original minimum and maximum
summary(concrete$strength)
# create training and test data
concrete_train <- concrete_norm[1:773, ]
concrete_test <- concrete_norm[774:1030, ]
## Step 3: Training a model on the data ----
# train the neuralnet model
library(neuralnet)
# simple ANN with only a single hidden neuron
concrete_model <- neuralnet(formula = strength ~ cement + slag +
ash + water + superplastic +
coarseagg + fineagg + age,
data = concrete_train)
# visualize the network topology
plot(concrete_model)
## Step 4: Evaluating model performance ----
# obtain model results
model_results <- compute(concrete_model, concrete_test[1:8])
# obtain predicted strength values
predicted_strength <- model_results$net.result
# examine the correlation between predicted and actual values
cor(predicted_strength, concrete_test$strength)
## Step 5: Improving model performance ----
# a more complex neural network topology with 5 hidden neurons
concrete_model2 <- neuralnet(strength ~ cement + slag +
ash + water + superplastic +
coarseagg + fineagg + age,
data = concrete_train, hidden = 5)
# plot the network
plot(concrete_model2)
# evaluate the results as we did before
model_results2 <- compute(concrete_model2, concrete_test[1:8])
predicted_strength2 <- model_results2$net.result
cor(predicted_strength2, concrete_test$strength)
# visualize the network topology
plot(concrete_model)
# plot the network
plot(concrete_model2)
## Step 6: Really crank it ----
# a more complex neural network topology with 10 hidden neurons
concrete_model3 <- neuralnet(strength ~ cement + slag +
ash + water + superplastic +
coarseagg + fineagg + age,
data = concrete_train, hidden = 10)
# plot the network
plot(concrete_model3)
# evaluate the results as we did before
model_results3 <- compute(concrete_model3, concrete_test[1:8])
predicted_strength3 <- model_results3$net.result
cor(predicted_strength3, concrete_test$strength)
## Step 6: Really crank it ----
# a more complex neural network topology with 50 hidden neurons
concrete_model3 <- neuralnet(strength ~ cement + slag +
ash + water + superplastic +
coarseagg + fineagg + age,
data = concrete_train, hidden = 50)
# plot the network
plot(concrete_model3)
## Step 6: Really crank it ----
# a more complex neural network topology with 20 hidden neurons, done in layers
concrete_model3 <- neuralnet(strength ~ cement + slag +
ash + water + superplastic +
coarseagg + fineagg + age,
data = concrete_train, hidden = c(10,6,4))
# plot the network
plot(concrete_model3)
# plot the network
plot(concrete_model3)
# evaluate the results as we did before
model_results3 <- compute(concrete_model3, concrete_test[1:8])
predicted_strength3 <- model_results3$net.result
cor(predicted_strength3, concrete_test$strength)
#set wd
setwd("~/Documents/Academics Grad School/PubPol 683 Elections and Campaigns/Elections")
#set wd
setwd("~/Documents/Academics Grad School/PubPol 683 Elections and Campaigns/Elections")
#set wd
setwd("~/Academics Grad School/PubPol 683 Elections and Campaigns/Elections")
## Import Shapefiles
library(rgdal)
install.packages("rgdal")
## Import Shapefiles
library(rgdal)
wash_precincts <- readOGR(
dsn= paste0(getwd(),"VotingPrecinct")
)
wash_precincts <- readOGR(
dsn= gwd(),
layer = "VotingPrecinct"
)
wash_precincts <- readOGR(
dsn= getwd(),
layer = "VotingPrecinct"
)
summary(wash_precincts)
wash_precincts$NAME
wash_precincts$JURISDICTI
wash_precincts$JURISDICTI == "City of Ann Arbor"
wash_precincts <- wash_precincts[wash_precincts$JURISDICTI == "City of Ann Arbor"]
wash_precincts <- wash_precincts[wash_precincts$JURISDICTI == "City of Ann Arbor",]
summary(wash_precincts)
wash_precincts$NAME
library(broom)
wash_precincts <- readOGR(
dsn= getwd(),
layer = "VotingPrecinct"
)
#summary(wash_precincts)
A2_precincts <- wash_precincts[wash_precincts$JURISDICTI == "City of Ann Arbor",]
A2_df <- tidy(A2_precincts, region = "NAME")
library(broom)
A2_df <- tidy(A2_precincts, region = "NAME")
?tidy
install.packages("gpclib")
A2_df <- tidy(A2_precincts, region = "NAME")
A2_df <- tidy(A2_precincts, region = "NAME")
install.packages("rgeos")
A2_df <- tidy(A2_precincts, region = "NAME")
A2_df <- tidy(A2_precincts, region = "NAME")
install.packages("rgdal")
install.packages("rgdal")
A2_df <- tidy(A2_precincts, region = "NAME")
## Import Shapefiles
library(rgdal)
library(broom)
A2_df <- tidy(A2_precincts, region = "NAME")
# Plot it
library(ggplot2)
ggplot() +
geom_polygon(data = A2_precincts, aes( x = long, y = lat, group = group), fill="#69b3a2", color="white") +
theme_void()
wash_precincts <- readOGR(
dsn= paste0(getwd(),"/Voting Precinct/"),
layer = "VotingPrecinct"
)
wash_precincts <- readOGR(
dsn= paste0(getwd(),"/Voting Precinct/"),
layer = "VotingPrecinct"
)
paste0(getwd(),"/Voting Precinct/")
#set wd
setwd("~/Academics Grad School/PubPol 683 Elections and Campaigns/Elections")
wash_precincts <- readOGR(
dsn= paste0(getwd(),"/Voting Precinct/"),
layer = "VotingPrecinct"
)
## Import Shapefiles
library(rgdal)
wash_precincts <- readOGR(
dsn= paste0(getwd(),"/Voting Precinct/"),
layer = "VotingPrecinct"
)
